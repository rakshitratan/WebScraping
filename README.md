# WebScraping

When it comes to analyze data. The most important task of an analyst before analysis is to collect data. In the journey of becoming an data analyst, we use data sources with formatted data, but later as we expand our horizon we have to collect data from different sources and format that accordingly for our analysis. 

In this repository you will find three projects of collecting data from different websites.
1.	Web Scraping the Wikipedia table: “https://en.wikipedia.org/wiki/List_of_S%26P_500_companies”
2.	Ireland Subway Locations: " https://restaurants.subway.com/ireland”
3.	Scraping the List: Female CEOs of the S&P 500 Companies: https://www.catalyst.org/research/women-ceos-of-the-sp-500/ 


<H2>
Software used:
•	Python
•	Jupiter notebook
</H2>
Python Libraries used:
•	Urllib – For requesting the webpages
•	Request – For requesting the webpages
•	BeautifulSoup – WebScraping tool for parsing the HTML
•	Pandas - For creating the data frame and standard library for organizing data
